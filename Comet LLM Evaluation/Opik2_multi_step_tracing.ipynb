{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xROyQYP1DM9"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/opik-logo.svg\" width=\"250\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ScvGXUo3I80"
      },
      "source": [
        "# Tracking a Multi-step LLM Chain\n",
        "\n",
        "In this exercise, you'll track a multi-step LLM chain with Opik. You can use OpenAI or open source models via LiteLLM.\n",
        "\n",
        "If you have multiple steps in your LLM pipeline, you can use the `track` decorator to log the traces for each step. If OpenAI is called within one of these steps, the LLM call with be associated with that corresponding step:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YJRuver_SmK"
      },
      "source": [
        "# Imports & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ6cxMoh3cpS"
      },
      "outputs": [],
      "source": [
        "%pip install opik openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhy3HZn63ce4"
      },
      "outputs": [],
      "source": [
        "from opik import track\n",
        "import opik\n",
        "from opik.integrations.openai import track_openai\n",
        "from openai import OpenAI\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPIK_PROJECT_NAME\"] = \"Multi-step-Chain-Demo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThX2YArw3mda"
      },
      "outputs": [],
      "source": [
        "# opik configs\n",
        "if \"OPIK_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPIK_API_KEY\"] = getpass.getpass(\"Enter your Opik API key: \")\n",
        "\n",
        "opik.configure()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T52NO_R73qb3"
      },
      "outputs": [],
      "source": [
        "# openai configs\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "client = OpenAI()\n",
        "openai_client = track_openai(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kWBXxTzzVHJ"
      },
      "source": [
        "* Using open-source model from HuggingFace with LiteLLM instead of OpenAI above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IknQHhv-zhWP",
        "outputId": "b69a8bab-6847-49ce-f8ee-e5fdeedb6f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m297.0/302.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/6.5 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install opik litellm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epSy4SjHzw9z",
        "outputId": "bc081ad6-2a5a-49dc-b0f3-d05e537c65ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
            "* 'fields' has been removed\n",
            "  warnings.warn(message, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Opik API key: ··········\n",
            "Do you want to use \"bluemusk\" workspace? (Y/n)y\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OPIK: Configuration saved to file: /root/.opik.config\n"
          ]
        }
      ],
      "source": [
        "import opik\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Define your OPIK project name to log traces with @track decorator\n",
        "os.environ[\"OPIK_PROJECT_NAME\"] = \"Multi-step-Chain-Demo\"\n",
        "\n",
        "if \"OPIK_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPIK_API_KEY\"] = getpass.getpass(\"Enter your Opik API key: \")\n",
        "\n",
        "opik.configure()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B4zEH55e06Kp"
      },
      "outputs": [],
      "source": [
        "from litellm.integrations.opik.opik import OpikLogger\n",
        "from opik.opik_context import get_current_span_data\n",
        "from opik import track\n",
        "import litellm\n",
        "\n",
        "opik_logger = OpikLogger()\n",
        "# In order to log LiteLLM traces to Opik, you will need to set the Opik callback\n",
        "litellm.callbacks = [opik_logger]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VuB5vbJ1KkG",
        "outputId": "d3e4898f-8647-4ef4-c54c-e269a2ae5814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face API key: ··········\n"
          ]
        }
      ],
      "source": [
        "# set Hugging Face API key to access meta-llama3\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"HF_TOKEN\" not in os.environ:\n",
        "    os.environ[\"HF_TOKEN\"] = getpass.getpass(\"Enter your Hugging Face API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCOFr4Wd4Frj"
      },
      "source": [
        "# Define First Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZJToIZM6pR5v"
      },
      "outputs": [],
      "source": [
        "@track\n",
        "def generate_meal(ingredient):\n",
        "    prompt = f\"Generate one example of a meal that can be made with {ingredient}.\"\n",
        "    res = litellm.completion(\n",
        "        model=\"huggingface/meta-llama/Llama-3.2-1B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return res.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-1R6q7W4JnZ"
      },
      "source": [
        "# Define Second Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z_iBzyQgpvEo"
      },
      "outputs": [],
      "source": [
        "@track\n",
        "def generate_recipe(meal):\n",
        "    prompt = f\"Generate a step-by-step recipe for {meal}\"\n",
        "    res = litellm.completion(\n",
        "        model=\"huggingface/meta-llama/Llama-3.2-1B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return res.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Wc5RDhCaJs"
      },
      "source": [
        "# Call Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "K6WmeCQ4p6js",
        "outputId": "779ce128-007a-4f1d-853e-fbcea6354fbc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Here's a step-by-step recipe for Garlic Chicken Fajitas:\\n\\n**Servings:** 4-6 people\\n\\n**Cooking Time:** 20-25 minutes\\n\\n**Prep Time:** 10 minutes\\n\\n**Total Time:** 30-35 minutes\\n\\n**Step-by-Step Instructions:**\\n\\n1. **Prepare the ingredients:**\\n\\t* Rinse the chicken breast and pat it dry with paper towels.\\n\\t* Peel and mince the garlic cloves.\\n\\t* Slice the onion\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@track\n",
        "def generate_recipe_from_ingredient(ingredient):\n",
        "    meal = generate_meal(ingredient)\n",
        "    story = generate_recipe(meal)\n",
        "    return story\n",
        "\n",
        "generate_recipe_from_ingredient(\"garlic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fRPxqyFq83h"
      },
      "source": [
        "# Try with your own example!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "SYgndLdprBQ3",
        "outputId": "acf90c0f-3724-47f8-fbcc-92cc83934cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter an ingredient: Jollof rice\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Here's a step-by-step recipe for Jollof Rice with Chicken and Vegetables:\\n\\n**Servings:** 4-6 people\\n\\n**Cooking Time:** 30-40 minutes\\n\\n**Prep Time:** 15 minutes\\n\\n**Total Time:** 45-55 minutes\\n\\n**Step-by-Step Instructions:**\\n\\n**Step 1: Prepare the Chicken**\\n\\n1. In a large bowl, whisk together 2 tablespoons of vegetable oil, 1 teaspoon of salt, and 1\""
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_recipe_from_ingredient(input(\"Enter an ingredient: \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtlHxdBU9HQD"
      },
      "source": [
        "## Trying another example not related to ingredient and meal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rRAg3c_v9LVd"
      },
      "outputs": [],
      "source": [
        "# First step\n",
        "\n",
        "@track\n",
        "def get_product(product):\n",
        "    prompt = f\"What is the best name to describe a company that makes {product}?\"\n",
        "    res = litellm.completion(\n",
        "        model=\"huggingface/meta-llama/Llama-3.2-1B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return res.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "imgKauFp971D"
      },
      "outputs": [],
      "source": [
        "# Second step\n",
        "\n",
        "@track\n",
        "def get_company(company_name):\n",
        "  prompt = f\"Write a 20 words description for the following company: {company_name}\"\n",
        "  res = litellm.completion(\n",
        "        model=\"huggingface/meta-llama/Llama-3.2-1B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "  )\n",
        "  return res.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "QNjcY_iD-s3H",
        "outputId": "da55fd16-c794-4f03-8e4c-dd3a74e6de30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Here are 20-word descriptions for each of the company name suggestions:\\n\\n1. **Kickoff Sports**: Kickstart your passion for football with a company that embodies the excitement and energy of the game.\\n2. **Field & Co.**: Experience the thrill of football with a company that's dedicated to providing top-notch gear and expert advice.\\n3. **Gridiron Gear**: Elevate your game with a company that's all about delivering high-quality football equipment and expert guidance.\\n4. **Kickoff\""
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Call chain of both steps above\n",
        "\n",
        "@track\n",
        "def describe_company(product):\n",
        "  company = get_product(product)\n",
        "  description = get_company(company)\n",
        "  return description\n",
        "\n",
        "# Run the chain\n",
        "describe_company('football')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-qW9aYgDQrv"
      },
      "source": [
        "* Note: refresh Opik UI to see updated projects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYUplINNDcVn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2YJRuver_SmK",
        "rCOFr4Wd4Frj",
        "M-1R6q7W4JnZ",
        "H_Wc5RDhCaJs",
        "4fRPxqyFq83h"
      ],
      "name": "Opik2-multi-step-tracing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "comet-eval",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
